[{"fold": 1, "Training Loss": 0.17317000018476053, "Test Loss": 0.8598153352737427, "Test Accur.": 0.7466666666666667, "0 Accur.": 0.7777777777777778, "1 Accur.": 0.8181818181818182, "2 Accur.": 0.6538461538461539, "f1": [[0.8076923076923077, 0.7422680412371134, 0.6868686868686869], 0.7456096785993692], "prec": [[0.84, 0.6792452830188679, 0.723404255319149], 0.74993524993525], "rec": [[0.7777777777777778, 0.8181818181818182, 0.6538461538461539], 0.7475498461126723]}, {"fold": 2, "Training Loss": 0.2645034969372805, "Test Loss": 0.6019716680049896, "Test Accur.": 0.8, "0 Accur.": 0.8, "1 Accur.": 0.8148148148148148, "2 Accur.": 0.782608695652174, "f1": [[0.8510638297872342, 0.8073394495412846, 0.7422680412371134], 0.8002237735218775], "prec": [[0.9090909090909091, 0.8, 0.7058823529411765], 0.7991411701556629], "rec": [[0.8, 0.8148148148148148, 0.782608695652174], 0.8049910873440286]}, {"fold": 3, "Training Loss": 0.18883507924024448, "Test Loss": 0.5650501996278763, "Test Accur.": 0.8066666666666666, "0 Accur.": 0.82, "1 Accur.": 0.8166666666666667, "2 Accur.": 0.775, "f1": [[0.836734693877551, 0.8032786885245902, 0.775], 0.8050044608007138], "prec": [[0.8541666666666666, 0.7903225806451613, 0.775], 0.8038888888888889], "rec": [[0.82, 0.8166666666666667, 0.775], 0.8064964157706093]}, {"fold": 4, "Training Loss": 0.2856506731274516, "Test Loss": 0.5828756988048553, "Test Accur.": 0.8133333333333334, "0 Accur.": 0.9230769230769231, "1 Accur.": 0.8541666666666666, "2 Accur.": 0.66, "f1": [[0.8727272727272727, 0.811881188118812, 0.7415730337078651], 0.8087271648513167], "prec": [[0.8275862068965517, 0.7735849056603774, 0.8461538461538461], 0.81241452991453], "rec": [[0.9230769230769231, 0.8541666666666666, 0.66], 0.8157749862369251]}, {"fold": 5, "Training Loss": 0.20519032797148062, "Test Loss": 0.5440799176692963, "Test Accur.": 0.8066666666666666, "0 Accur.": 0.7804878048780488, "1 Accur.": 0.9038461538461539, "2 Accur.": 0.7368421052631579, "f1": [[0.8311688311688312, 0.8245614035087719, 0.7706422018348624], 0.8087908121708219], "prec": [[0.8888888888888888, 0.7580645161290323, 0.8076923076923077], 0.807058687995787], "rec": [[0.7804878048780488, 0.9038461538461539, 0.7368421052631579], 0.8182152375700763]}, {"fold": 6, "Training Loss": 0.1642501741474451, "Test Loss": 0.5318572700023652, "Test Accur.": 0.8466666666666667, "0 Accur.": 0.8235294117647058, "1 Accur.": 0.9387755102040817, "2 Accur.": 0.78, "f1": [[0.8749999999999999, 0.8518518518518519, 0.8125], 0.8464506172839505], "prec": [[0.9333333333333333, 0.7796610169491526, 0.8478260869565217], 0.8474349739895958], "rec": [[0.8235294117647058, 0.9387755102040817, 0.78], 0.8536068124130024]}, {"fold": 7, "Training Loss": 0.2618883434076642, "Test Loss": 0.705480545759201, "Test Accur.": 0.76, "0 Accur.": 0.8166666666666667, "1 Accur.": 0.8444444444444444, "2 Accur.": 0.6, "f1": [[0.8376068376068376, 0.7524752475247526, 0.6585365853658536], 0.7495395568324813], "prec": [[0.8596491228070176, 0.6785714285714286, 0.7297297297297297], 0.7537037037037037], "rec": [[0.8166666666666667, 0.8444444444444444, 0.6], 0.7559834270360586]}, {"fold": 8, "Training Loss": 0.23049735225910364, "Test Loss": 0.5155164301395416, "Test Accur.": 0.8133333333333334, "0 Accur.": 0.7551020408163265, "1 Accur.": 0.8461538461538461, "2 Accur.": 0.8367346938775511, "f1": [[0.8314606741573034, 0.830188679245283, 0.7809523809523811], 0.8142005781183226], "prec": [[0.925, 0.8148148148148148, 0.7321428571428571], 0.8126635269492413], "rec": [[0.7551020408163265, 0.8461538461538461, 0.8367346938775511], 0.8239858906525573]}, {"fold": 9, "Training Loss": 0.28145325911599534, "Test Loss": 0.5802899420261383, "Test Accur.": 0.8333333333333334, "0 Accur.": 0.8541666666666666, "1 Accur.": 0.8979591836734694, "2 Accur.": 0.7547169811320755, "f1": [[0.9111111111111111, 0.7927927927927928, 0.8080808080808081], 0.8373282373282374], "prec": [[0.9761904761904762, 0.7096774193548387, 0.8695652173913043], 0.8356142771574039], "rec": [[0.8541666666666666, 0.8979591836734694, 0.7547169811320755], 0.8518110376455397]}, {"fold": 10, "Training Loss": 0.28605023754197495, "Test Loss": 0.4220007210969925, "Test Accur.": 0.84, "0 Accur.": 0.9333333333333333, "1 Accur.": 0.8936170212765957, "2 Accur.": 0.7241379310344828, "f1": [[0.8936170212765957, 0.8076923076923077, 0.823529411764706], 0.8416129135778698], "prec": [[0.8571428571428571, 0.7368421052631579, 0.9545454545454546], 0.8503627618814705], "rec": [[0.9333333333333333, 0.8936170212765957, 0.7241379310344828], 0.8495101389838231]}]